# -*- coding: utf-8 -*-
"""train

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WuprUOlqVwDVRaRUs1-E92ahMJFJv4ic
"""

model = UNet(2,
             depth=param.unet_depth,
             start_filts=param.unet_start_filters,
             merge_mode='concat').cuda()
optim = torch.optim.Adam(model.parameters(), lr=param.lr)

def get_loss(dl, model):
    loss = 0
    for X, y in dl:
        X, y = X.cuda(), y.cuda()
        output = model(X)
        loss += F.cross_entropy(output, y.argmax(dim=1)).item()
    return loss / len(dl)

def iou_pytorch(pred, target, smooth=1e-6):
    """
    Вычисляет IoU (Jaccard Index) между предсказанной и истинной масками.
    :param pred: (batch_size, num_classes, H, W) - предсказания модели (логиты)
    :param target: (batch_size, H, W) - истинные метки класса для каждого пикселя
    :param smooth: малое число для избежания деления на 0
    """
    pred = torch.argmax(pred, dim=1)  # Переводим логиты в классы
    intersection = (pred & target).float().sum((1, 2))  # Пересечение (AND)
    union = (pred | target).float().sum((1, 2))  # Объединение (OR)
    iou = (intersection + smooth) / (union + smooth)  # IoU для каждого изображения
    return iou.mean().item()  # Среднее по батчу


def train_model(model, train_dl, val_dl, optimizer, epochs, log_interval):

    iters = []
    t_iou = []
    v_iou = []

    for epoch in range(epochs):
        model.train()  # Включаем режим обучения
        train_loss = 0
        train_iou = 0  # Для накопления IoU

        for batch_idx, (X, y) in enumerate(train_dl):
            X, y = X.cuda(), y.cuda()  # Перенос на GPU
            optimizer.zero_grad()  # Обнуляем градиенты
            output = model(X)  # Прогон через сеть
            loss = F.cross_entropy(output, y.argmax(dim=1))  # Вычисляем loss
            loss.backward()  # Обратное распространение ошибки
            optimizer.step()  # Обновление весов

            train_loss += loss.item()
            train_iou += iou_pytorch(output, y.argmax(dim=1))  # Вычисляем IoU

            # Логирование каждые log_interval шагов
            #if batch_idx % log_interval == 0:
                #print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_dl)}, Loss: {loss.item():.4f}, IoU: {iou_pytorch(output, y.argmax(dim=1)):.4f}')

        # Усредняем loss и IoU по всем батчам
        train_loss /= len(train_dl)
        train_iou /= len(train_dl)
        t_iou.append(train_iou)


        # Валидация
        model.eval()  # Включаем режим валидации
        val_loss, val_iou = 0, 0
        with torch.no_grad():  # Отключаем вычисление градиентов
            for X, y in val_dl:
                X, y = X.cuda(), y.cuda()
                output = model(X)
                val_loss += F.cross_entropy(output, y.argmax(dim=1)).item()
                val_iou += iou_pytorch(output, y.argmax(dim=1))

        val_loss /= len(val_dl)
        val_iou /= len(val_dl)
        v_iou.append(val_iou)
        iters.append(epoch + 1)



        print(f'>>> Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train IoU = {train_iou:.4f}, Val Loss = {val_loss:.4f}, Val IoU = {val_iou:.4f}')
    return iters, t_iou, v_iou

    iters, t_iou, v_iou = train_model(model, train_dl, val_dl, optim, epochs=param.epochs, log_interval=param.log_interval)